---
title: "Take-home Exercise 3"
author: "Stefanie Felicia"
date: "10 June 2025"
date-modified: "last-modified"
format: html
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
---

## 1.1 Background

Over the past decade, the community of Oceanus has undergone transformations and challenges evolving from its fishing-centric origins. Currently, people are shifting to another investment, i.e. ocean tourism industry, which creates a growing tension. With the growing tourism, it attracted international pop star Sailor Shift who wanted to shoot his/her new music video in the island.

Clepper Jensen, a journalist who has been observing the tension going on, focused on the temporary closure of Nemo Reef. By using investigative tools to intercept radio communication, he uncovered a complex web of expedited approvals and secretive logistics, in which I will be helping him to:

-   Use visual analytics to help Clepper understand and explore the interactions and relationships between people and vessels that relates to environmentalism (known associates of Green Guardians), Sailor Shift, and fishing/leisure vessels.

-   Investigate Nadia Conti as she was previously entangled in an illegal fishing scheme, and it is suspected that she may have continued illegal activity within Oceanus, so we want to use visual analytics to provide evidence whether sheâ€™s doing something illegal.

## 1.2 Objective

The purpose of this take-home exercise is to:

-   Evaluate and determine the necessary R packages needed for Shiny Application which are supported in R CRAN

-   Prepare storyboards for the visual analytics project

-   Prepare and test specific R codes and ensure it returns the expected output

-   Select appropriate Shiny UI components for exposing the paremeters

## 1.3 The Data

The project examines data from The Vast Challenge 2025 the <a href ="https://vast-challenge.github.io/2025/MC3.html">Mini Challenge 3</a>. The dataset contains the 2 weeks of radio intercept by Clepper Jansen to uncover communications between people, group and organizations in Oceanus. The dataset is a graph network consisting of 1159 nodes and 3226 edges. Each node represents entity (people, organizations or groups), event or relationship, whereas edges represent relationship (i.e. sender and receiver).

## 1.4 Methodology

1\. Data preparation:

-   Cleaning data for necessary analysis to arrive unto a truthful conclusion

-   Filtering out nodes into people, organization and group

2\. Data Visualization Techniques:

-   Timeline Graph: is used to tie together exchanges sent, received or mentioned Nadia Conti

-   Data Table

## 1.5 Import Libraries

```{r}
pacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph, knitr, DT, stringr, cronologia, tidytext, dplyr)
```

## 1.6 Import Data

```{r}
MC3 <- fromJSON("data/MC3_graph.json")
MC3_schema <- fromJSON("data/MC3_schema.json")
```

Before preparing the data, we'll check the structure of the knowledge graph.

```{r}
glimpse(MC3)
```

## 2.1 Data Preparation

::: panel-tabset
## 2.2 Extract Edges and Nodes Tables

The `as_tibble()` function is used to extract nodes and links tibble data frame from MC3 tibble data frame.

```{r}
mc3_nodes <- as_tibble(MC3$nodes) 
mc3_edges <- as_tibble(MC3$edges)
```

## 2.3 Initial EDA

We'll use `ExpCatViz()` from SmartEDA library to reveal frequency distribution of all categorical fields from mc3_nodes.

```{r}
ExpCatViz(data=mc3_nodes, col="lightblue")
```

## 2.4 Data Cleaning Node

The following steps are taken to clean the **nodes**:

-   Convert values in id into character data type

-   Exclude record with id that are missing

-   Exclude records with similar id values

-   Exclude *thing_collected* field

```{r}
mc3_nodes_cleaned <- mc3_nodes %>%   mutate(id = as.character(id)) %>%   filter(!is.na(id)) %>%   distinct(id, .keep_all = TRUE) %>%   select(-thing_collected)
```

## 2.5 Data Cleaning Edges

Next, the following steps are taken to clean the **edges**:

-   Rename source *column* into *from_id* and *target* column into *to_id*

-   Convert values in *from_id* and *to_id* column into character data type

-   Exclude values in from_id and to_id that's not found in the id column from *mc3_nodes_cleaned*

-   Exclude records where *from_id* and *to_id*, or *from_id* or *to_id* is missing

```{r}
mc3_edges_cleaned <- mc3_edges %>%       rename(from_id = source,               to_id = target) %>%       mutate(across(c(from_id, to_id),                      as.character)) %>%       filter(from_id %in% mc3_nodes_cleaned$id,               to_id %in% mc3_nodes_cleaned$id) %>%       filter(!is.na(from_id), !is.na(to_id))
```

A new dataframe from the existing data frame (*mc3_nodes_cleaned*) and *.row_id* column is added which assigns unique row number to each row number (works like row index). Then we select *id* and .*row_id* columns whereas other columns are dropped.

```{r}
node_index_lookup <- mc3_nodes_cleaned %>%   mutate(.row_id = row_number()) %>%   select(id, .row_id)
```

Then from_id and to_id columns in mc_edges_indexed are converted it to integer indices. The rows with unmatched nodes are also dropped.

```{r}
mc3_edges_indexed <- mc3_edges_cleaned %>%   left_join(node_index_lookup,              by = c("from_id" = "id")) %>%   rename(from = .row_id) %>%   left_join(node_index_lookup,              by = c("to_id" = "id")) %>%   rename(to = .row_id) %>%   select(from, to, is_inferred, type) %>%   filter(!is.na(from) & !is.na(to))
```

Next, the node list will only include nodes that are used in the edge list and new indices are assigned

```{r}
used_node_indices <- sort(unique(c(mc3_edges_indexed$from, mc3_edges_indexed$to)))
mc3_nodes_final <- mc3_nodes_cleaned %>%   
  slice(used_node_indices) %>%   
  mutate(new_index = row_number())
```

The lookup is rebuild from old index to new index.

```{r}
old_to_new_index <- tibble(old_index = used_node_indices, new_index = seq_along(used_node_indices))
```

Then, we'll update edge indices to match new node table

```{r}
mc3_edges_final <- mc3_edges_indexed %>%   left_join(old_to_new_index,              by = c("from" = "old_index")) %>%   rename(from_new = new_index) %>%   left_join(old_to_new_index,              by = c("to" = "old_index")) %>%   rename(to_new = new_index) %>%   select(from = from_new, to = to_new,           is_inferred, type)
```

## 2.6 Build tidygraph Object

```{r}
mc3_graph <- tbl_graph(nodes = mc3_nodes_final,   edges = mc3_edges_final,   directed = TRUE)
```

```{r}
str(mc3_graph)
```

Next, we'll set a seed to ensure reproducibility.

```{r}
set.seed(1234)
```
:::

## 3.1 Data Analysis

### 3.2 Interaction and Relationship of Entities to Each Other

### 3.3 Nadia Conti Communications 
To know if Nadia is involved in illegal activities, we can check her exchanges with other people, organization and organization. Who does she frequently communicate with and what do they frequently talk about. 
```{r}
comm_about_nadia <- mc3_graph %>%
  activate(nodes) %>%
  filter(str_detect(content, "Nadia Conti| Nadia | Conti ")) %>%
  distinct(content, .keep_all = TRUE)

timeline_nadia_comm <- comm_about_nadia %>%
  as_tibble(active = "nodes")

timeline_nadia_comm <- timeline_nadia_comm %>%
  mutate(
  timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S"),
    timestamp_desc = format(timestamp, "%A, %B %d %Y, %H:%M"))

timeline_nadia <- create_tml(df=timeline_nadia_comm, smr="timestamp_desc", dsc="content", smr_bgcol = "#613659", dsc_col = "#613659")
timeline_nadia
```

### 4.1 Storyboard from Data Analysis

Input

Output

Storyboard

<https://giniceseah.netlify.app/posts/2021-07-31-storyboard/>

\`\`\`
